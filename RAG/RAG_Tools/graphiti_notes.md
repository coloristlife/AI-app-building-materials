- https://zread.ai/getzep/graphiti

  
**What Makes Graphiti Unique**
  Traditional knowledge graphs often struggle with dynamic data and temporal context. Graphiti addresses these challenges through several key innovations:

  - Real-Time Incremental Updates
  Graphiti processes new data episodes immediately without requiring batch recomputation, enabling real-time knowledge graph updates as new information becomes available.
  
  - Bi-Temporal Data Model
  The framework explicitly tracks both when events occurred and when they were ingested into the system, allowing for accurate point-in-time historical queries and temporal reasoning.
  
  - Efficient Hybrid Retrieval
  Combining semantic embeddings, keyword search (BM25), and graph traversal, Graphiti achieves low-latency queries without relying on computationally expensive LLM summarization.
  
  - Custom Entity Definitions
  Developers can create flexible ontologies and define custom entity types using straightforward Pydantic models, enabling domain-specific knowledge representations.

**Core Architecture**

Graphiti's architecture is built around several key components that work together to create a temporal knowledge graph system:

---

### **Data Processing Pipeline**

The framework processes data through **episodes**, which are discrete units of information that can be messages, JSON objects, or plain text. Each episode is analyzed to extract entities and relationships, which are then integrated into the graph with temporal context.

---

### **Graph Structure**

The knowledge graph consists of three main node types:

* **Entity Nodes:** Represent real-world entities (people, organizations, concepts)
* **Episodic Nodes:** Capture the temporal context of when information was learned
* **Community Nodes:** Group related entities for higher-level reasoning

---

### **Search and Retrieval System**

Graphiti employs a sophisticated search architecture that combines multiple retrieval methods:

* **Semantic search** using vector embeddings
* **Keyword search** using BM25
* **Graph-based traversal** for contextual relationships

**Key Features Comparison**

| **Feature**            | **Graphiti**          | **Traditional RAG** | **GraphRAG**             |
| ---------------------- | --------------------- | ------------------- | ------------------------ |
| **Temporal Awareness** | Bi-temporal tracking  | Basic timestamps    | Limited temporal support |
| **Update Method**      | Real-time incremental | Batch processing    | Batch-oriented           |
| **Search Latency**     | Sub-second            | Seconds to minutes  | Tens of seconds          |
| **Custom Entities**    | Yes                   | Limited             | No                       |
| **Scalability**        | High                  | Moderate            | Moderate                 |
| **Historical Queries** | Precise point-in-time | Limited             | Basic                    |



**Supported Database Backends**

**Graphiti** supports several graph database backends, giving you flexibility to choose the one that best suits your infrastructure and deployment needs:

| **Database**       | **Type**     | **Best For**                                         | **Setup Complexity** |
| ------------------ | ------------ | ---------------------------------------------------- | -------------------- |
| **Neo4j**          | Native Graph | General-purpose applications with a mature ecosystem | üü° Medium            |
| **FalkorDB**       | Redis-based  | Lightweight deployments and high-speed operations    | üü¢ Low               |
| **Amazon Neptune** | Cloud-native | Enterprise-scale, managed service environments       | üî¥ High              |
| **Kuzu**           | Embedded     | Local development, testing, and prototyping          | üü¢ Low               |




## üîó Integration Ecosystem

**Graphiti** integrates seamlessly with the modern AI and data ecosystem, providing flexibility across model providers, deployment modes, and observability tools.

---

### ü§ñ LLM Providers

Graphiti supports multiple large language model backends, with **OpenAI** as the default:

* OpenAI
* Google Gemini
* Anthropic Claude
* Groq
* Azure OpenAI

---

### ‚öôÔ∏è Deployment Options

Choose the setup that fits your workflow and infrastructure:

* **Standalone Python library** ‚Äì integrate directly into your application code
* **REST API service** ‚Äì interact via standard HTTP endpoints
* **MCP (Model Context Protocol) server** ‚Äì enable context sharing across AI agents
* **Docker containerization** ‚Äì deploy easily in cloud or on-prem environments

---

### üìà Monitoring and Observability

Graphiti provides built-in hooks for monitoring and performance visibility:

* **OpenTelemetry tracing** ‚Äì end-to-end operation tracking
* **Performance metrics** ‚Äì latency and throughput insights
* **Debug logging** ‚Äì granular visibility for troubleshooting

---

### üß† When to Use Graphiti

Use **Graphiti** when you need:

* Real-time knowledge integration from dynamic data sources
* Temporal reasoning and historical query capabilities
* Custom entity and relationship definitions for domain-specific applications
* Low-latency search without LLM summarization overhead
* Scalable, graph-based knowledge infrastructure

---

### üí° Ideal Use Cases

* AI agent memory systems
* Enterprise knowledge management
* Conversational AI with contextual persistence
* Temporal data analysis and reasoning
* Personalization engines with evolving user profiles



