memgraph
- https://github.com/memgraph/memgraph


Open-source graph database, tuned for dynamic analytics environments. Easy to adopt, scale and own.

- https://zread.ai/memgraph/memgraph/1-overview

Memgraph is an in-memory graph database compatible with Neo4j that delivers exceptional performance through its C/C++ implementation. It supports the Cypher query language, provides ACID compliance, and offers advanced features like streaming integration, custom query modules, and high availability replication.


- https://zread.ai/memgraph/memgraph/12-cypher-query-engine
  


ANTLR4-generated grammar to parse Cypher queries into an Abstract Syntax Tree (AST)

## from AI

Here’s a detailed walkthrough of how the process works when using ANTLR4‑generated grammar to parse a query language like Cypher into an Abstract Syntax Tree (AST). I’ll break it down step‑by‑step and tie it back to how a system (like a graph‑database frontend) using a `Parser` class might use it.

---

## 1. Grammar definition (lexer + parser)

First, you define a grammar that describes the syntax of Cypher queries. This involves two components:

* **Lexer grammar**: Specifies how raw text is broken into *tokens* (identifiers, keywords like `MATCH`, `WHERE`, symbols like `(`, `)`, relationship arrows, etc.).
* **Parser grammar**: Specifies how tokens combine into valid structures (clauses like `MATCH (n)-[r]->(m) RETURN n, m`, patterns, expressions, etc.).

When you run ANTLR4 on these `.g4` grammar files, it will generate code (in your target language, e.g., Java, C++, etc.) that includes a Lexer class and a Parser class for that language. ([Strumenta][1])

---

## 2. Lexing & parsing input

When a user submits a Cypher query string (e.g., `"MATCH (a)-[r:REL]->(b) WHERE a.name = 'Alice' RETURN b"`), here's what happens:

1. The raw string is fed into the generated Lexer. The lexer scans the characters and groups them into tokens (e.g., `MATCH`, `(`, `a`, `)`, `-`, `[`, `r`, `:`, `REL`, `]`, `->`, `(`, `b`, `)`, `WHERE`, `a`, `.`, `name`, `=`, `'Alice'`, `RETURN`, `b`).
2. The sequence of tokens is then passed to the generated Parser. The parser uses the grammar rules to **recognize** valid structures according to the grammar (for example: a MATCH clause followed by pattern, optional WHERE clause, then a RETURN clause). During parsing, a *parse tree* (often also called a concrete syntax tree) is constructed. ([Medium][2])

The parse tree shows all the details of how the input matched grammar rules. It might include intermediate nodes corresponding directly to grammar productions, punctuation tokens, parentheses, etc.

---

## 3. Obtaining an AST from the parse tree

While the parse tree is faithful to the grammar structure, many systems prefer to then **transform** it into an Abstract Syntax Tree (AST) — which is a simplified, cleaned‐up tree representing the essential logical structure of the query, stripped of unnecessary syntax noise. (According to best‐practice tutorials: “Technically what you get from ANTLR is a parse tree rather than an AST.”) ([Strumenta][1])

### Why transform to AST

* The AST removes extraneous details (parentheses, punctuation, redundant rule‑nodes) that don’t matter for semantic or execution phases. ([Strumenta][3])
* It provides a cleaner, more intuitive representation of the query (e.g., “MATCH pattern → WHERE condition → RETURN projections”) rather than every tiny grammar node.
* It decouples the grammar representation from further phases (semantic analysis, optimization, execution). If grammar changes, only the parse step might change, not the rest of the system. ([Strumenta][3])

### How transformation is done

* Often using a **Visitor** or **Listener** mechanism provided by ANTLR4:

  * A *Visitor* traverses the parse tree nodes, and returns or constructs appropriate AST nodes for each relevant rule. For example, when encountering the rule `matchClause`, the visitor might create an AST node `MatchClauseNode` having a child `PatternNode`.
  * A *Listener* could also be used, but typically for building AST the Visitor pattern is more convenient because you return values (AST nodes) rather than just side‑effects. ([GitHub][4])
* In the conversion:

  * Some parse tree nodes are skipped/dropped (e.g., punctuation tokens like commas, parentheses).
  * Some parse tree structures may be collapsed: multiple grammar rules may map to a single AST node type.
  * AST node classes/types are defined in your system to represent key constructs: e.g., `ReturnClause`, `WhereCondition`, `PatternMatch`, `NodePattern`, `RelationshipPattern`, etc.
  * For each parse tree context (generated by the grammar), you implement a `visitXyz(...)` method to return the AST node corresponding to that context. This visitor builds up the AST recursively. For example from StackOverflow:

    > “ANTLR generated the CST nodes for us … We now have to convert these to AST nodes … This is easily done with a visitor” ([Stack Overflow][5])

---

## 4. Example walkthrough

Let’s take a concrete example of a simple Cypher‐like query and walk how the parsing → AST transformation might occur.

### Input

```cypher
MATCH (a:Person)-[r:KNOWS]->(b:Person)
WHERE a.age > 30
RETURN b.name
```

### Parsing (rough steps)

* Lexer tokenizes: `MATCH`, `(`, `a`, `:`, `Person`, `)`, `-`, `[`, `r`, `:`, `KNOWS`, `]`, `->`, `(`, `b`, `:`, `Person`, `)`, `WHERE`, `a`, `.`, `age`, `>`, `30`, `RETURN`, `b`, `.`, `name`
* Parser recognizes rule `query → matchClause whereClause? returnClause`

  * `matchClause` rule sees pattern node `(a:Person)-[r:KNOWS]->(b:Person)`
  * `whereClause` rule sees expression `a.age > 30`
  * `returnClause` rule sees projection `b.name`
* Parse tree represents these with many nodes: `MatchClauseContext`, `NodePatternContext`, `RelationshipPatternContext`, `WhereClauseContext`, `ExpressionContext`, etc, along with nodes for punctuation and tokens.

### AST building

* The visitor begins at the root parse tree node (say `QueryContext`) and calls `visitQuery()`.
* Inside `visitQuery`, it may call `visitMatchClause()`, `visitWhereClause()` (if present), `visitReturnClause()`.
* `visitMatchClause()` returns an AST node `MatchClauseNode` with children: `PatternNode`.
* The `PatternNode` might have children: `NodePatternNode(a:Person)`, `RelationshipPatternNode(r:KNOWS)`, `NodePatternNode(b:Person)`.
* `visitWhereClause()` returns an AST node `WhereClauseNode` with child `ComparisonExpressionNode(left=PropertyAccessNode(a, age), operator='>', right=LiteralNode(30))`.
* `visitReturnClause()` returns `ReturnClauseNode` with child `PropertyAccessNode(b, name)`.
* The overall AST might look like:

```
QueryNode
 ├─ MatchClauseNode
 │    └─ PatternNode
 │         ├─ NodePatternNode(var=a, label=Person)
 │         ├─ RelationshipPatternNode(var=r, type=KNOWS, direction=->)
 │         └─ NodePatternNode(var=b, label=Person)
 ├─ WhereClauseNode
 │    └─ ComparisonExpressionNode(
 │          left=PropertyAccessNode(a, age),
 │          operator='>',
 │          right=LiteralNode(30)
 │        )
 └─ ReturnClauseNode
      └─ PropertyAccessNode(b, name)
```

* Notice the AST doesn’t include tokens like `(`, `)`, `:`, `->`, as separate nodes—they are used in parsing but not necessary for the semantics in the AST.

---

## 5. Next steps after AST

Once you have the AST, the `Parser` class (or front‑end pipeline) will pass this AST downstream to later phases:

* **Semantic analysis**: Check that variables used are defined, labels/types exist, property references are valid, relationship directions are allowed, etc.
* **Query rewriting / optimization**: The AST may be transformed (e.g., flattening clauses, rewriting patterns, adding implicit expansions).
* **Plan generation**: From AST build a logical plan (graph‑operators: scan, filter, join, project) and then a physical plan.
* **Execution**: The engine executes the plan against the graph database.

The transformation from parse tree → AST is crucial because it ensures that the execution engine works on a clean, semantically meaningful representation of the query, rather than raw grammar artifacts.

---

## 6. Key takeaways for your system

* Define your grammar carefully: as you extend support for Cypher constructs (e.g., `OPTIONAL MATCH`, `UNWIND`, `WITH`, etc) your grammar files need to cover them accurately.
* Use ANTLR4 generated parser/lexer to reduce manual parsing boilerplate.
* Build a visitor (or tree walker) that converts the parse tree into your custom AST node classes.
* Design your AST to reflect the logical structure you need (clauses, patterns, expressions) and drop or collapse grammar/lexical noise.
* Use the AST for the rest of frontend pipeline (semantic checks, planning) — this separation gives you clarity and maintainability.



[1]: https://tomassetti.me/antlr-mega-tutorial/?utm_source=chatgpt.com "The ANTLR Mega Tutorial - Federico Tomassetti"
[2]: https://medium.com/%40jenniferwarwickk/antlr4-cd4ed25a7e95?utm_source=chatgpt.com "ANTLR4. Parsing, Analysing, and Compiling with…"
[3]: https://tomassetti.me/best-practices-for-antlr-parsers/?utm_source=chatgpt.com "Best Practices for ANTLR Parsers - Federico Tomassetti"
[4]: https://github.com/antlr/antlr4/discussions/4590?utm_source=chatgpt.com "Building an AST · antlr antlr4 · Discussion #4590"
[5]: https://stackoverflow.com/questions/29971097/how-to-create-ast-with-antlr4?utm_source=chatgpt.com "How to create AST with ANTLR4?"
